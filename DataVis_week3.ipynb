{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laura-cheesmanhaynes/DSDA-Data-Visualisation/blob/main/DataVis_week3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previous session's Google Colab:\n",
        "https://colab.research.google.com/drive/1NevtJilm7h9-CvmZNuWtqyikK-aB_Ud2?usp=sharing"
      ],
      "metadata": {
        "id": "xzm3vYjm55eF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading a .ods file instructions as follows:"
      ],
      "metadata": {
        "id": "t8ahaQIr6AQF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gGO71ub453Ee",
        "outputId": "c205db12-d5fb-444d-accc-f83eb4d090d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting odfpy\n",
            "  Downloading odfpy-1.4.1.tar.gz (717 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m717.0/717.0 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from odfpy) (0.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Building wheels for collected packages: odfpy\n",
            "  Building wheel for odfpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for odfpy: filename=odfpy-1.4.1-py2.py3-none-any.whl size=160673 sha256=806d7c62a7a0ebb287a0a9d394e258248eba01d8b19acec12c6d965a04ff4c0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/2e/95/90d94fe33903786937f3b8c33dd88807f792359c6424b40469\n",
            "Successfully built odfpy\n",
            "Installing collected packages: odfpy\n",
            "Successfully installed odfpy-1.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas odfpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "tzX_lYIk6HL3",
        "outputId": "850d0218-a191-4e64-8e20-7f555dff35e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading .ods file into pandas data frame\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/gdrive/My Drive/YSJ-DataVis/MY_ODS_FILE.ods'\n",
        "df = pd.read_excel(file_path, engine='odf') # Notice engine='odf'"
      ],
      "metadata": {
        "id": "5z2hqdBy6fwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading specific sheets from .ods file into pandas data frame\n",
        "sheet_name = 'YourSheetName'  # Replace 'YourSheetName' with the actual name of your sheet\n",
        "df_specific_sheet = pd.read_excel(file_path, engine='odf', sheet_name=sheet_name)"
      ],
      "metadata": {
        "id": "rEyDb_3166vZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load All Sheets into a Dictionary of DataFrames\n",
        "all_sheets_dict = pd.read_excel(file_path, engine='odf', sheet_name=None)\n",
        "\n",
        "# Accessing a specific DataFrame from the dictionary\n",
        "df_sheet1 = all_sheets_dict['Sheet1']  # Replace 'Sheet1' with the actual name of your sheet"
      ],
      "metadata": {
        "id": "dlVl106Y7SeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Classroom Group Exercise**"
      ],
      "metadata": {
        "id": "qWMEHBL98Pge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise**\n",
        "\n",
        "Role: You are hired by the UK Driver and Vehicle Standards Agency (DVSA) to do some analysis on practical driving pass rates. You are provided the data on car pass rates by gender, month and test centre by DVSA. The data can be accessed from https://www.gov.uk/government/statistical-data-sets/car-driving-test-data-by-test-centre\n",
        "\n",
        "The data (dvsa0201.ods) can also be accessed from: https://drive.google.com/file/d/1IkWGs6PBwRO9e_gGx-pC2-H88vYgAc3y/view?usp=sharing\n",
        "\n",
        "\n",
        "Objectives (O):\n",
        "\n",
        "Using the lessons learned in Data Visualisation so far,\n",
        "- 1. Show the top 10 test centres with least pass rate in the latest year.\n",
        "- 2. Show the top 10 test centres with most pass rate  in the latest year.\n",
        "- 3. Show the pass rate for different genders in the top 10 test centres with least pass rate in the latest year.\n",
        "- 4. Show the pass rate for different genders in the top 10 test centres with most pass rate in the latest year.\n",
        "- 5. Which month period has the least pass rate for the top 10 test centres with least pass rate in the latest year.\n",
        "- 6. Which month period has the most pass rate for the top 10 test centres with least pass rate in the latest year.\n",
        "- 7. Which month preiod has the most pass rate for the top 10 test centres with most pass rate in the latest year.\n",
        "- 8. Which month period has the least pass rate for the top 10 test centres with most pass rate in the latest year.\n",
        "\n",
        "Discussion (D):\n",
        "\n",
        "- 1. Mention any preprocessing done (how and why) on the data for the above objectives (O.1-8).\n",
        "- 2. In your group, discuss what are the limitations of using matplotlib for the above data visualisation techniques?\n",
        "- 3. Will using mplfinance be useful for this type of data? If yes, then why or if not, then why?\n",
        "- 4. What other information/visuals you might want to show with the above visual representations (O.1-8)?"
      ],
      "metadata": {
        "id": "2Dg3IYiR8S0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Solution Hint**"
      ],
      "metadata": {
        "id": "QKNNcbJN_4xS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas odfpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbxYGxzw_84U",
        "outputId": "2fbf5756-4bd2-4983-e67b-9bb66a9327aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting odfpy\n",
            "  Downloading odfpy-1.4.1.tar.gz (717 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m717.0/717.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from odfpy) (0.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Building wheels for collected packages: odfpy\n",
            "  Building wheel for odfpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for odfpy: filename=odfpy-1.4.1-py2.py3-none-any.whl size=160673 sha256=71fbfab371899e5aaa13b621e74603e1a9b200bb12976da284d398d63829ac1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/2e/95/90d94fe33903786937f3b8c33dd88807f792359c6424b40469\n",
            "Successfully built odfpy\n",
            "Installing collected packages: odfpy\n",
            "Successfully installed odfpy-1.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGEMKTd8_-5p",
        "outputId": "d6e21f7b-bc41-4724-b6e5-50354d840040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading dvsa0201.ods file into pandas data frame\n",
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/gdrive/My Drive/YSJ-DataVis/dvsa0201.ods'\n",
        "df = pd.read_excel(file_path, engine='odf', sheet_name='2021-22')"
      ],
      "metadata": {
        "id": "mtKbtoDJCaNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Clean and preprocess the DataFrame as necessary\n",
        "# Assuming df is preprocessed and each row represents a test center's annual data\n",
        "\n",
        "'''\n",
        "\n",
        "Cleaning and preprocessing data is a crucial step before any analysis or visualization. Here are some techniques that you might employ for cleaning and preprocessing the dataset as follows:\n",
        "\n",
        "1. Handling Header Rows:\n",
        "   - If the first few rows are headers or merged cells, use the `header` parameter in `read_excel` to specify which row to use as the header.\n",
        "   - If there are multiple rows that serve as a header, consider using `header=[0,1]` (or more indices if necessary) to capture all the levels.\n",
        "\n",
        "2. Flattening Multi-Level Column Headers:\n",
        "   - If using multi-level headers from an Excel sheet, combine them into single-level headers after loading, for easier access.\n",
        "\n",
        "3. Dealing with Missing Values:\n",
        "   - Check for missing or `NaN` values using `df.isnull().any()`.\n",
        "   - Fill or impute missing values using methods like `.fillna()` or imputation techniques.\n",
        "\n",
        "4. Converting Data Types:\n",
        "   - Ensure numerical columns are in appropriate data types (e.g., integers or floats) using `df.astype()`.\n",
        "   - Convert strings to categorical data types where applicable to save memory and potentially speed up computations.\n",
        "\n",
        "5. Renaming Columns:\n",
        "   - Rename columns for consistency and ease of access, e.g., `df.rename(columns={'old_name': 'new_name'}, inplace=True)`.\n",
        "\n",
        "6. Removing Unnecessary Rows:\n",
        "   - Drop rows that don't contain data relevant to the analysis, such as summary or subtotal rows, using `df.drop()`.\n",
        "\n",
        "7. Normalizing Text Data:\n",
        "   - If any columns contain text data, consider standardizing the text by converting to lower/upper case, stripping whitespace, etc.\n",
        "\n",
        "8. Aggregating Data:\n",
        "   - If you need to aggregate monthly data into yearly data, use groupby or pivot techniques.\n",
        "   - Summarize data using `df.groupby()` if necessary for your analysis.\n",
        "\n",
        "9. Indexing:\n",
        "   - Set a meaningful index for the DataFrame, like test center names, using `df.set_index()`.\n",
        "\n",
        "10. Validating Data Consistency:\n",
        "    - Check for consistency in the data, especially if merging data from multiple sources, and look for duplicate entries.\n",
        "\n",
        "11. Calculating Derived Columns:\n",
        "    - Create new columns that might be useful for analysis, such as total tests conducted, or total pass rate, if these are not already present.\n",
        "\n",
        "12. Outlier Detection:\n",
        "    - Identify and handle outliers that could skew the analysis.\n",
        "\n",
        "13. Date and Time Parsing:\n",
        "    - If your dataset contains dates, make sure they are parsed correctly as datetime objects for proper time series analysis.\n",
        "\n",
        "Remember, the specific preprocessing steps will depend on the structure and quirks of your actual data.\n",
        "It's usually a good idea to start by inspecting the DataFrame using methods like `df.head()`, `df.info()`, and `df.describe()`\n",
        "to understand what preprocessing is needed.\n",
        "Sometimes, you can also create new temporary dataframes or sheets to hold the preprocessed data for the purpose.\n",
        "\n",
        "'''\n",
        "\n",
        "# Calculate the total pass rate for each test center if not already calculated\n",
        "# df['Total Pass Rate'] = (df['Passes'] / df['Conducted']) * 100  # Modify this line according to your DataFrame structure\n",
        "\n",
        "# Since the DataFrame is expected to have multi-level columns, you need to flatten these after loading the data\n",
        "df.columns = [' '.join(col).strip() for col in df.columns.values]\n",
        "\n",
        "# Find the Test Centers with the least total pass rate\n",
        "# Sorting by the total tests pass rate column\n",
        "least_pass_rates = df.sort_values(by='Total tests Pass rate (%)').head(10)\n",
        "\n",
        "# Visualization using matplotlib\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(least_pass_rates['Test Center Name'], least_pass_rates['Total tests Pass rate (%)'])  # You need to replace 'Test Center Name' with the actual name of your test center column\n",
        "plt.xlabel('Pass Rate (%)')\n",
        "plt.ylabel('Test Center')\n",
        "plt.title('Top 10 Test Centers with Least Pass Rate for Total Tests')\n",
        "plt.gca().invert_yaxis()  # To show the lowest rate at the top\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wDc18PG_Cp5R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}